{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7399377,"sourceType":"datasetVersion","datasetId":4302383}],"dockerImageVersionId":30357,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp -r /kaggle/input/* /kaggle/working/\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# yaml_content = \"\"\"\n# path: /kaggle/working/dlprojectcombined/Aerial car view yolo dataset\n# train: /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/images\n# val: /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/images\n\n# nc: 1\n# names: ['Car']\n\n# roboflow:\n#   workspace: aerial-person-detection\n#   project: aerial-person-detection\n#   version: 3\n#   license: CC BY 4.0\n#   url: https://universe.roboflow.com/aerial-person-detection/aerial-person-detection/dataset/3\n# \"\"\"\n\n# with open('/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml', 'w') as file:\n#     file.write(yaml_content)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:27.005264Z","iopub.execute_input":"2024-01-14T15:36:27.005988Z","iopub.status.idle":"2024-01-14T15:36:27.012213Z","shell.execute_reply.started":"2024-01-14T15:36:27.005947Z","shell.execute_reply":"2024-01-14T15:36:27.011192Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# yaml_content = \"\"\"\n# path: /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8\n# train: /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images\n# val: /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/valid/images\n\n# nc: 6\n# names: ['bicycle', 'bus', 'car', 'motorcycle', 'person', 'truck']\n\n# roboflow:\n#   workspace: aerial-person-detection\n#   project: aerial-person-detection\n#   version: 3\n#   license: CC BY 4.0\n#   url: https://universe.roboflow.com/aerial-person-detection/aerial-person-detection/dataset/3\n# \"\"\"\n\n# with open('/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml', 'w') as file:\n#     file.write(yaml_content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# yaml_content = \"\"\"\n# path: /kaggle/working/dlprojectcombined/Licence plate recognition\n# train: /kaggle/working/dlprojectcombined/Licence plate recognition/train/images\n# val: /kaggle/working/dlprojectcombined/Licence plate recognition/valid/images\n\n# nc: 1\n# names: ['license_plate']\n\n# roboflow:\n#   workspace: aerial-person-detection\n#   project: aerial-person-detection\n#   version: 3\n#   license: CC BY 4.0\n#   url: https://universe.roboflow.com/aerial-person-detection/aerial-person-detection/dataset/3\n# \"\"\"\n\n# with open('/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml', 'w') as file:\n#     file.write(yaml_content)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:58.082423Z","iopub.execute_input":"2024-01-14T15:35:58.083295Z","iopub.status.idle":"2024-01-14T15:35:58.089861Z","shell.execute_reply.started":"2024-01-14T15:35:58.083252Z","shell.execute_reply":"2024-01-14T15:35:58.088607Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# # Pip install method (recommended)\n# %pip install ultralytics\n# import ultralytics\n# ultralytics.checks()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Git clone method (for development)\n# !git clone https://github.com/ultralytics/ultralytics\n# %pip install -qe ultralytics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r working1.zip /kaggle/working/logs","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:05:44.965769Z","iopub.execute_input":"2024-01-14T16:05:44.966658Z","iopub.status.idle":"2024-01-14T16:06:06.315208Z","shell.execute_reply.started":"2024-01-14T16:05:44.966605Z","shell.execute_reply":"2024-01-14T16:06:06.314130Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"updating: kaggle/working/logs/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/results.csv (deflated 84%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/confusion_matrix.png (deflated 19%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch2_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/R_curve.png (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/PR_curve.png (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch0.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch4030.jpg (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/last.pt (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/best.pt (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch0_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch1.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch1_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/confusion_matrix_normalized.png (deflated 20%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch0_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch4032.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/P_curve.png (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/events.out.tfevents.1705229442.2a550455f085.27.5 (deflated 73%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch1_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/val_batch2_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch2.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/F1_curve.png (deflated 8%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/results.png (deflated 6%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/train_batch4031.jpg (deflated 8%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/train_batch0.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/labels.jpg (deflated 23%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/events.out.tfevents.1705229424.2a550455f085.27.4 (deflated 59%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/train_batch1.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/labels_correlogram.jpg (deflated 33%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00055/train_batch2.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/events.out.tfevents.1705229405.2a550455f085.27.3 (deflated 68%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/train_batch0.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/train_batch1.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00054/train_batch2.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/events.out.tfevents.1705228822.2a550455f085.27.0 (deflated 71%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 3%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/train_batch0.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/train_batch1.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/events.out.tfevents.1705229333.2a550455f085.27.1 (deflated 59%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/labels_correlogram.jpg (deflated 33%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/train_batch2.jpg (deflated 1%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00053/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00053/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00053/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00053/events.out.tfevents.1705229349.2a550455f085.27.2 (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.csv (deflated 84%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 21%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch2_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/R_curve.png (deflated 10%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/events.out.tfevents.1705238007.2a550455f085.27.7 (deflated 72%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch4030.jpg (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 31%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 31%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 21%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch4032.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/P_curve.png (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch2_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 10%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.png (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch4031.jpg (deflated 8%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.csv (deflated 84%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix.png (deflated 20%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch2_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/R_curve.png (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/events.out.tfevents.1705233937.2a550455f085.27.6 (deflated 73%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/PR_curve.png (deflated 6%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch4030.jpg (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix_normalized.png (deflated 19%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch4032.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/P_curve.png (deflated 5%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch2_labels.jpg (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/F1_curve.png (deflated 8%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.png (deflated 4%)\nupdating: kaggle/working/logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch4031.jpg (deflated 8%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/results.csv (deflated 72%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 7%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg (deflated 29%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 9%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/events.out.tfevents.1705242104.2a550455f085.27.8 (deflated 72%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/args.yaml (deflated 54%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 32%)\nupdating: kaggle/working/logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 7%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.csv (deflated 84%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix.png (deflated 42%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/R_curve.png (deflated 18%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/PR_curve.png (deflated 25%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 9%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 9%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/events.out.tfevents.1705247662.2a550455f085.27.16 (deflated 72%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/P_curve.png (deflated 21%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/F1_curve.png (deflated 17%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.png (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.csv (deflated 84%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 42%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/events.out.tfevents.1705246599.2a550455f085.27.11 (deflated 72%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 26%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 1%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 1%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 41%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/P_curve.png (deflated 18%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/args.yaml (deflated 54%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 1%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 15%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.png (deflated 6%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.csv (deflated 84%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix.png (deflated 42%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/PR_curve.png (deflated 25%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/P_curve.png (deflated 18%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/args.yaml (deflated 54%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/F1_curve.png (deflated 15%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.png (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/events.out.tfevents.1705246804.2a550455f085.27.12 (deflated 72%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.csv (deflated 82%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 27%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch2_pred.jpg (deflated 6%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/R_curve.png (deflated 16%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 23%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 8%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 8%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 8%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg (deflated 36%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 7%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 10%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 7%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 29%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 7%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/P_curve.png (deflated 19%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 7%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 29%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/events.out.tfevents.1705242631.2a550455f085.27.9 (deflated 73%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch2_labels.jpg (deflated 6%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 10%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 15%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.png (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.csv (deflated 83%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 41%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/events.out.tfevents.1705247004.2a550455f085.27.13 (deflated 71%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 26%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 10%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/P_curve.png (deflated 21%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/args.yaml (deflated 54%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 16%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.png (deflated 5%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/results.csv (deflated 77%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 8%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 6%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 7%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg (deflated 36%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/events.out.tfevents.1705245425.2a550455f085.27.10 (deflated 74%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 10%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 29%)\n  adding: kaggle/working/logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 10%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/results.csv (deflated 83%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/confusion_matrix.png (deflated 41%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/PR_curve.png (deflated 23%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 8%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 8%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/P_curve.png (deflated 17%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/events.out.tfevents.1705248087.2a550455f085.27.18 (deflated 71%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/F1_curve.png (deflated 15%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/results.png (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/results.csv (deflated 83%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/confusion_matrix.png (deflated 42%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/PR_curve.png (deflated 25%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/events.out.tfevents.1705247218.2a550455f085.27.14 (deflated 71%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/last.pt (deflated 9%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt (deflated 9%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch0_pred.jpg (deflated 3%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/P_curve.png (deflated 19%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/args.yaml (deflated 54%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/F1_curve.png (deflated 16%)\n  adding: kaggle/working/logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/results.png (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.csv (deflated 83%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 42%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/R_curve.png (deflated 17%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 26%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 1%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 10%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 10%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 1%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/events.out.tfevents.1705247429.2a550455f085.27.15 (deflated 71%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/P_curve.png (deflated 20%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 1%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 16%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/results.png (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.csv (deflated 83%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix.png (deflated 41%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/R_curve.png (deflated 16%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch200.jpg (deflated 6%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch201.jpg (deflated 3%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/PR_curve.png (deflated 21%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch0.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/ (stored 0%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt (deflated 7%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt (deflated 7%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg (deflated 24%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch1.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_labels.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/confusion_matrix_normalized.png (deflated 39%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch0_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/P_curve.png (deflated 17%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/events.out.tfevents.1705247868.2a550455f085.27.17 (deflated 71%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/val_batch1_pred.jpg (deflated 4%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch202.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/args.yaml (deflated 55%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels_correlogram.jpg (deflated 33%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/train_batch2.jpg (deflated 5%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/F1_curve.png (deflated 15%)\n  adding: kaggle/working/logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/results.png (deflated 6%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'working1.zip')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:06:15.404388Z","iopub.execute_input":"2024-01-14T16:06:15.404845Z","iopub.status.idle":"2024-01-14T16:06:15.413305Z","shell.execute_reply.started":"2024-01-14T16:06:15.404803Z","shell.execute_reply":"2024-01-14T16:06:15.412190Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/working1.zip","text/html":"<a href='working1.zip' target='_blank'>working1.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train YOLOv8n on COCO128 for 300 epochs\nfrom ultralytics import YOLO\n# !yolo task=detect mode=train model=yolov8n.pt data=/kaggle/input/aerial-view-car-detection-for-yolov5/mydata.yaml epochs=300 imgsz=640 batch=32 cache=disk\nmodel = YOLO('yolov8n.pt')\nsave_dir = '/kaggle/working/ultralytics/runs'\nos.makedirs(save_dir, exist_ok=True)\n# result = model.train(data='/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml', epochs = 2, project = save_dir)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:50:42.114360Z","iopub.execute_input":"2024-01-14T10:50:42.115300Z","iopub.status.idle":"2024-01-14T10:50:42.184457Z","shell.execute_reply.started":"2024-01-14T10:50:42.115257Z","shell.execute_reply":"2024-01-14T10:50:42.183567Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# import csv\n# from ultralytics import YOLO\n# import os\n\n# # Define a YOLOv8n model\n# model = YOLO('yolov8n.pt')\n\n# # Define the hyperparameters to tune\n# lr0_values = [0.001, 0.1]\n# momentum_values = [0.8, 0.99]\n# weight_decay_values = [0.0005]\n# optimizer = 'Adam'\n# epochs = 20\n\n# # Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset\n# best_loss = float('inf')\n# best_hyperparameters = {}\n\n# data = '/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml'\n\n# with open('hyperparameters1.csv', mode='w') as csv_file:\n#     fieldnames = ['lr0', 'momentum', 'weight_decay', 'val_loss']\n#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n#     writer.writeheader()\n\n#     for lr0 in lr0_values:\n#         for momentum in momentum_values:\n#             for weight_decay in weight_decay_values:\n#                 save_dir = f'logs/learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}'\n#                 os.makedirs(save_dir, exist_ok=True)\n#                 result = model.train(data=data, lr0=lr0, momentum=momentum, weight_decay=weight_decay, optimizer=optimizer, epochs=epochs,\n#                                      plots=True, project=save_dir, name=f'learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}' )\n\n#                 writer.writerow({'lr0': lr0, 'momentum': momentum, 'weight_decay': weight_decay})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:50:42.186050Z","iopub.execute_input":"2024-01-14T10:50:42.186357Z","iopub.status.idle":"2024-01-14T14:26:36.661545Z","shell.execute_reply.started":"2024-01-14T10:50:42.186313Z","shell.execute_reply":"2024-01-14T14:26:36.658233Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"New https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/learning-rate0.001_momentum0.8_weight_decay0.0005, name=learning-rate0.001_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056\nOverriding model.yaml nc=80 with nc=6\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \nModel summary: 225 layers, 3012018 parameters, 3012002 gradients\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/labels.cache... 6445 images, 0 backgrounds, 0 corrupt: 100%|| 6445/6445 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000137_02220_d_0000163_jpg.rf.c76c4efa8d7cb12599ecbc67c1fb7afb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000140_00118_d_0000002_jpg.rf.6ac6b72a99c9fff9561b50b9dafbe0a3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999945_00000_d_0000114_jpg.rf.58b19b78116cb3d88b3b8a65de976d4b.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999987_00000_d_0000049_jpg.rf.b2ddd3f8fac21d1a5131495d6f2cd563.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/valid/labels.cache... 545 images, 0 backgrounds, 0 corrupt: 100%|| 545/545 [00:00<?, ?it/s]\nPlotting labels to logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/20      10.2G      1.808      1.774      1.037        713        640: 100%|| 403/403 [03:58<00:00,  1.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.32it/s]\n                   all        545      36988      0.242      0.211      0.179      0.096\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/20      5.58G      1.698      1.384     0.9992        979        640: 100%|| 403/403 [03:54<00:00,  1.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.41it/s]\n                   all        545      36988      0.505      0.241       0.24      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/20        10G      1.656      1.302     0.9881       1218        640: 100%|| 403/403 [03:55<00:00,  1.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.47it/s]\n                   all        545      36988       0.36      0.264      0.263       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/20      9.91G      1.624       1.25     0.9793       1177        640: 100%|| 403/403 [03:53<00:00,  1.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.27it/s]\n                   all        545      36988      0.503      0.269      0.263      0.143\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/20      10.2G      1.592      1.213      0.973       1403        640: 100%|| 403/403 [03:53<00:00,  1.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.53it/s]\n                   all        545      36988      0.378      0.289      0.294      0.168\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/20      7.12G      1.575      1.179     0.9676       1469        640: 100%|| 403/403 [03:56<00:00,  1.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.53it/s]\n                   all        545      36988      0.393      0.303      0.308      0.173\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/20       6.8G      1.548      1.155     0.9637       1439        640: 100%|| 403/403 [03:52<00:00,  1.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.34it/s]\n                   all        545      36988      0.369      0.301      0.304       0.17\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/20      8.38G      1.547      1.144     0.9617        904        640: 100%|| 403/403 [03:54<00:00,  1.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.48it/s]\n                   all        545      36988      0.464      0.297      0.314      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/20      10.1G       1.53      1.125     0.9563       1384        640: 100%|| 403/403 [03:54<00:00,  1.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.53it/s]\n                   all        545      36988      0.425      0.305       0.31      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/20      9.78G      1.506      1.102     0.9524       1167        640: 100%|| 403/403 [03:52<00:00,  1.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.45it/s]\n                   all        545      36988      0.436      0.323      0.333      0.189\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/20       8.9G      1.483       1.09     0.9536        767        640: 100%|| 403/403 [03:14<00:00,  2.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.57it/s]\n                   all        545      36988      0.428      0.325      0.327      0.187\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/20      7.14G      1.471       1.06     0.9486        523        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.44it/s]\n                   all        545      36988      0.463       0.32      0.334      0.188\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/20       8.5G       1.46      1.045     0.9477        605        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.42it/s]\n                   all        545      36988      0.438      0.331      0.341      0.195\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/20      9.71G      1.447      1.029     0.9441        650        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:06<00:00,  2.62it/s]\n                   all        545      36988      0.451       0.34      0.345      0.198\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/20       7.4G      1.436      1.018     0.9412        601        640: 100%|| 403/403 [03:09<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.43it/s]\n                   all        545      36988      0.445      0.349      0.354      0.204\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/20      8.23G      1.427     0.9986     0.9396        763        640: 100%|| 403/403 [03:09<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.47it/s]\n                   all        545      36988      0.464      0.344      0.356      0.207\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/20      8.17G      1.417      0.987     0.9365        493        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.39it/s]\n                   all        545      36988      0.486      0.335      0.357      0.208\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/20      8.99G      1.403     0.9736      0.932        630        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:06<00:00,  2.62it/s]\n                   all        545      36988      0.464      0.347      0.361      0.209\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/20      10.2G      1.392     0.9615     0.9297        655        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.43it/s]\n                   all        545      36988      0.468      0.348      0.363       0.21\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/20      8.36G       1.38     0.9468     0.9276        673        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:20<00:00,  1.13s/it]\n                   all        545      36988      0.471      0.352       0.37      0.215\n\n20 epochs completed in 1.239 hours.\nOptimizer stripped from logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/last.pt, 6.2MB\nOptimizer stripped from logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/best.pt, 6.2MB\n\nValidating logs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3006818 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:19<00:00,  1.08s/it]\n                   all        545      36988       0.47      0.352       0.37      0.215\n               bicycle        545       1283      0.245      0.039     0.0532     0.0178\n                   bus        545        251      0.486      0.398      0.409      0.283\n                   car        545      13986      0.635      0.709      0.722      0.485\n            motorcycle        545       4861      0.501      0.264        0.3      0.118\n                person        545      13890      0.481      0.343      0.357      0.136\n                 truck        545       2717      0.473      0.361      0.376      0.249\nSpeed: 0.4ms preprocess, 2.1ms inference, 0.0ms loss, 1.2ms postprocess per image\nResults saved to \u001b[1mlogs/learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00056\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/learning-rate0.001_momentum0.99_weight_decay0.0005, name=learning-rate0.001_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \nModel summary: 225 layers, 3012018 parameters, 3012002 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/labels.cache... 6445 images, 0 backgrounds, 0 corrupt: 100%|| 6445/6445 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000137_02220_d_0000163_jpg.rf.c76c4efa8d7cb12599ecbc67c1fb7afb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000140_00118_d_0000002_jpg.rf.6ac6b72a99c9fff9561b50b9dafbe0a3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999945_00000_d_0000114_jpg.rf.58b19b78116cb3d88b3b8a65de976d4b.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999987_00000_d_0000049_jpg.rf.b2ddd3f8fac21d1a5131495d6f2cd563.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/valid/labels.cache... 545 images, 0 backgrounds, 0 corrupt: 100%|| 545/545 [00:00<?, ?it/s]\nPlotting labels to logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/20      8.91G      1.466      1.053     0.9468        549        640: 100%|| 403/403 [03:23<00:00,  1.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.45it/s]\n                   all        545      36988      0.433      0.328       0.33      0.187\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/20       8.6G      1.466      1.047     0.9462        368        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.49it/s]\n                   all        545      36988      0.475      0.335       0.35      0.198\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/20      10.9G      1.469      1.055     0.9475        615        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.36it/s]\n                   all        545      36988      0.448      0.326       0.34       0.19\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/20      10.2G       1.47      1.056     0.9494        611        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.53it/s]\n                   all        545      36988      0.469      0.323      0.335      0.188\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/20      7.76G      1.474      1.061     0.9508        745        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.55it/s]\n                   all        545      36988      0.464      0.328       0.34      0.192\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/20      9.38G      1.464      1.048     0.9495        618        640: 100%|| 403/403 [03:09<00:00,  2.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.43it/s]\n                   all        545      36988      0.435      0.345      0.347      0.197\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/20      12.9G      1.448      1.033     0.9453        482        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.38it/s]\n                   all        545      36988      0.451      0.338      0.347      0.196\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/20      7.18G      1.446       1.03     0.9443        553        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.52it/s]\n                   all        545      36988      0.437      0.324      0.342      0.191\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/20      10.3G      1.436      1.013     0.9419        376        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.47it/s]\n                   all        545      36988      0.462      0.336      0.358      0.204\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/20      6.39G      1.426      1.004     0.9386        597        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.40it/s]\n                   all        545      36988      0.467      0.336      0.348        0.2\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/20      8.94G      1.419      0.989     0.9358        767        640: 100%|| 403/403 [03:15<00:00,  2.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:06<00:00,  2.58it/s]\n                   all        545      36988      0.486       0.34      0.361      0.208\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/20      7.18G      1.418     0.9836     0.9337        523        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.52it/s]\n                   all        545      36988      0.464      0.349      0.362      0.205\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/20      8.53G      1.411     0.9717     0.9339        605        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.40it/s]\n                   all        545      36988      0.484      0.347      0.372      0.213\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/20      9.75G      1.388     0.9524     0.9275        650        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.55it/s]\n                   all        545      36988      0.492      0.347       0.37      0.214\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/20      7.43G      1.386      0.948     0.9271        601        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.40it/s]\n                   all        545      36988      0.477      0.356      0.376      0.216\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/20      8.26G      1.377     0.9339     0.9264        763        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.28it/s]\n                   all        545      36988      0.497      0.352      0.378      0.217\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/20      8.21G      1.373     0.9317     0.9242        493        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:06<00:00,  2.60it/s]\n                   all        545      36988      0.484      0.356      0.374      0.214\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/20      9.02G      1.361      0.922     0.9204        630        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.46it/s]\n                   all        545      36988      0.497       0.36      0.382      0.221\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/20      10.3G      1.355     0.9122     0.9203        655        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.38it/s]\n                   all        545      36988      0.479      0.365      0.382      0.222\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/20      8.39G      1.345     0.9007     0.9187        673        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:20<00:00,  1.15s/it]\n                   all        545      36988      0.476      0.372      0.385      0.222\n\n20 epochs completed in 1.121 hours.\nOptimizer stripped from logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3006818 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:19<00:00,  1.11s/it]\n                   all        545      36988      0.477      0.371      0.385      0.222\n               bicycle        545       1283      0.269      0.053     0.0598      0.023\n                   bus        545        251      0.501      0.434      0.446      0.294\n                   car        545      13986      0.615      0.729      0.732      0.494\n            motorcycle        545       4861      0.466      0.304      0.316      0.124\n                person        545      13890       0.49      0.357      0.372      0.142\n                 truck        545       2717      0.522      0.349      0.384      0.254\nSpeed: 0.4ms preprocess, 2.1ms inference, 0.0ms loss, 1.2ms postprocess per image\nResults saved to \u001b[1mlogs/learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/learning-rate0.1_momentum0.8_weight_decay0.0005, name=learning-rate0.1_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \nModel summary: 225 layers, 3012018 parameters, 3012002 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/labels.cache... 6445 images, 0 backgrounds, 0 corrupt: 100%|| 6445/6445 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000137_02220_d_0000163_jpg.rf.c76c4efa8d7cb12599ecbc67c1fb7afb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000140_00118_d_0000002_jpg.rf.6ac6b72a99c9fff9561b50b9dafbe0a3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999945_00000_d_0000114_jpg.rf.58b19b78116cb3d88b3b8a65de976d4b.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999987_00000_d_0000049_jpg.rf.b2ddd3f8fac21d1a5131495d6f2cd563.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/valid/labels.cache... 545 images, 0 backgrounds, 0 corrupt: 100%|| 545/545 [00:00<?, ?it/s]\nPlotting labels to logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/20      8.89G      2.203      1.996      1.244        549        640: 100%|| 403/403 [03:13<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:10<00:00,  1.66it/s]\n                   all        545      36988      0.277     0.0958      0.071     0.0379\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/20      8.58G      2.182      1.959      1.262        368        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.43it/s]\n                   all        545      36988       0.31     0.0772     0.0695     0.0365\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/20      10.8G      2.157      1.927      1.258        615        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.50it/s]\n                   all        545      36988      0.181      0.147      0.114     0.0537\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/20      10.1G      2.096      1.852      1.243        611        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.32it/s]\n                   all        545      36988      0.346       0.16      0.128     0.0646\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/20      7.74G      2.047       1.78      1.221        745        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.27it/s]\n                   all        545      36988      0.383      0.157      0.132     0.0664\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/20      9.36G      1.997      1.703      1.199        618        640: 100%|| 403/403 [03:11<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.29it/s]\n                   all        545      36988      0.388       0.17      0.145      0.078\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/20      12.9G      1.966      1.662      1.184        482        640: 100%|| 403/403 [03:13<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.40it/s]\n                   all        545      36988      0.403      0.177      0.151     0.0802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/20      7.16G      1.933      1.639      1.169        553        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.57it/s]\n                   all        545      36988      0.442      0.205      0.174     0.0924\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/20      10.3G      1.914      1.611      1.163        376        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.37it/s]\n                   all        545      36988      0.396      0.213      0.169     0.0949\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/20      6.37G      1.884       1.58       1.15        597        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:06<00:00,  2.59it/s]\n                   all        545      36988      0.444      0.195      0.179     0.0948\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/20      8.91G      1.861      1.555       1.14        767        640: 100%|| 403/403 [03:15<00:00,  2.06it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.51it/s]\n                   all        545      36988      0.468      0.209      0.186      0.102\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/20      7.16G      1.842      1.528      1.129        523        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.38it/s]\n                   all        545      36988      0.459      0.215      0.194      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/20      8.51G      1.828      1.507      1.125        605        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.42it/s]\n                   all        545      36988      0.481      0.214      0.201      0.107\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/20      9.72G      1.797      1.469      1.113        650        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.52it/s]\n                   all        545      36988      0.481      0.206      0.202      0.111\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/20      7.41G      1.777      1.454      1.107        601        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.31it/s]\n                   all        545      36988      0.288      0.214      0.197      0.107\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/20      8.24G      1.744      1.417      1.097        763        640: 100%|| 403/403 [03:10<00:00,  2.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.37it/s]\n                   all        545      36988      0.471      0.222      0.219      0.122\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/20      8.19G      1.724      1.391      1.087        493        640: 100%|| 403/403 [03:11<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.54it/s]\n                   all        545      36988      0.456      0.235      0.219      0.121\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/20         9G      1.701      1.359      1.079        630        640: 100%|| 403/403 [03:10<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.48it/s]\n                   all        545      36988      0.356      0.245       0.24      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/20      10.2G      1.666      1.323      1.066        655        640: 100%|| 403/403 [03:12<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.54it/s]\n                   all        545      36988      0.521      0.237      0.239      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/20      8.37G       1.63      1.283      1.057        673        640: 100%|| 403/403 [03:12<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:17<00:00,  1.04it/s]\n                   all        545      36988      0.358      0.257      0.254      0.141\n\n20 epochs completed in 1.124 hours.\nOptimizer stripped from logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3006818 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:16<00:00,  1.10it/s]\n                   all        545      36988      0.358      0.256      0.254      0.141\n               bicycle        545       1283          0          0     0.0158    0.00592\n                   bus        545        251      0.403      0.215      0.194      0.123\n                   car        545      13986      0.579      0.631      0.631      0.411\n            motorcycle        545       4861      0.475      0.142      0.196     0.0667\n                person        545      13890      0.411      0.258      0.252     0.0873\n                 truck        545       2717      0.282      0.293      0.234       0.15\nSpeed: 0.4ms preprocess, 1.9ms inference, 0.0ms loss, 1.3ms postprocess per image\nResults saved to \u001b[1mlogs/learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/learning-rate0.1_momentum0.99_weight_decay0.0005, name=learning-rate0.1_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \nModel summary: 225 layers, 3012018 parameters, 3012002 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/labels.cache... 6445 images, 0 backgrounds, 0 corrupt: 100%|| 6445/6445 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000137_02220_d_0000163_jpg.rf.c76c4efa8d7cb12599ecbc67c1fb7afb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/0000140_00118_d_0000002_jpg.rf.6ac6b72a99c9fff9561b50b9dafbe0a3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999945_00000_d_0000114_jpg.rf.58b19b78116cb3d88b3b8a65de976d4b.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/train/images/9999987_00000_d_0000049_jpg.rf.b2ddd3f8fac21d1a5131495d6f2cd563.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial Person Detection.v3-changed-labels.yolov8/valid/labels.cache... 545 images, 0 backgrounds, 0 corrupt: 100%|| 545/545 [00:00<?, ?it/s]\nPlotting labels to logs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/20      8.93G      1.725      1.383      1.088        549        640: 100%|| 403/403 [03:14<00:00,  2.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 18/18 [00:07<00:00,  2.36it/s]\n                   all        545      36988       0.47      0.204      0.199      0.102\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/20      5.48G      1.828       1.49      1.131        652        640:  32%|      | 128/403 [00:59<02:08,  2.13it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1462172775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 result = model.train(data=data, lr0=lr0, momentum=momentum, weight_decay=weight_decay, optimizer=optimizer, epochs=epochs,\n\u001b[0;32m---> 32\u001b[0;31m                                      plots=True, project=save_dir, name=f'learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}' )\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_batch_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m# Warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import csv\n# from ultralytics import YOLO\n# import os\n\n# # Define a YOLOv8n model\n# model = YOLO('yolov8n.pt')\n\n# # Define the hyperparameters to tune\n# lr0_values = [0.001, 0.1]\n# momentum_values = [0.8, 0.99]\n# weight_decay_values = [0.0005]\n# optimizer = 'Adam'\n# epochs = 10\n\n# # Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset\n# best_loss = float('inf')\n# best_hyperparameters = {}\n\n# data = '/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml'\n\n# with open('hyperparameters_license_plate.csv', mode='w') as csv_file:\n#     fieldnames = ['lr0', 'momentum', 'weight_decay', 'val_loss']\n#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n#     writer.writeheader()\n\n#     for lr0 in lr0_values:\n#         for momentum in momentum_values:\n#             for weight_decay in weight_decay_values:\n#                 save_dir = f'logs/licenceplate-learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}'\n#                 os.makedirs(save_dir, exist_ok=True)\n#                 result = model.train(data=data, lr0=lr0, momentum=momentum, weight_decay=weight_decay, optimizer=optimizer, epochs=epochs,\n#                                      plots=True, project=save_dir, name=f'learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}' )\n\n#                 writer.writerow({'lr0': lr0, 'momentum': momentum, 'weight_decay': weight_decay})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:14:20.517810Z","iopub.execute_input":"2024-01-14T16:14:20.518288Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"New https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005, name=learning-rate0.001_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/train/labels.cache... 21173 images, 28 backgrounds, 0 corrupt: 100%|| 21173/21173 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/valid/labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|| 2046/2046 [00:00<?, ?it/s]\nPlotting labels to logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      2.81G      1.258      0.853      1.212          5        640: 100%|| 1324/1324 [04:25<00:00,  4.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.12it/s]\n                   all       2046       2132       0.95      0.856      0.938      0.588\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      2.73G      1.217     0.6704       1.22          5        640: 100%|| 1324/1324 [04:19<00:00,  5.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.22it/s]\n                   all       2046       2132      0.953      0.897      0.948      0.576\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      2.73G      1.189     0.6251      1.209          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.17it/s]\n                   all       2046       2132       0.96      0.924      0.953      0.583\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      2.73G      1.157     0.5793      1.193          5        640: 100%|| 1324/1324 [04:17<00:00,  5.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.981      0.918      0.967      0.644\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      2.73G      1.143     0.5534       1.19          5        640: 100%|| 1324/1324 [04:16<00:00,  5.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.975      0.937       0.97      0.641\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      2.73G      1.123     0.5199       1.18          5        640: 100%|| 1324/1324 [04:16<00:00,  5.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.15it/s]\n                   all       2046       2132      0.975       0.94      0.969      0.661\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      2.73G        1.1     0.4963      1.168          4        640: 100%|| 1324/1324 [04:16<00:00,  5.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.21it/s]\n                   all       2046       2132       0.98      0.943      0.974      0.669\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      2.73G      1.081     0.4707      1.155          5        640: 100%|| 1324/1324 [04:17<00:00,  5.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.976      0.945      0.977      0.678\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      2.73G      1.061     0.4492      1.145          5        640: 100%|| 1324/1324 [04:17<00:00,  5.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.21it/s]\n                   all       2046       2132      0.979      0.945      0.979      0.679\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/10      2.73G      1.038     0.4287      1.125          5        640: 100%|| 1324/1324 [04:20<00:00,  5.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.56it/s]\n                   all       2046       2132       0.98      0.951      0.982      0.685\n\n10 epochs completed in 0.767 hours.\nOptimizer stripped from logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/weights/last.pt, 6.2MB\nOptimizer stripped from logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/weights/best.pt, 6.2MB\n\nValidating logs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.66it/s]\n                   all       2046       2132       0.98      0.951      0.982      0.685\nSpeed: 0.4ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/licenceplate-learning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.00052\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005, name=learning-rate0.001_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/train/labels.cache... 21173 images, 28 backgrounds, 0 corrupt: 100%|| 21173/21173 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/valid/labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|| 2046/2046 [00:00<?, ?it/s]\nPlotting labels to logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      2.82G      1.085     0.5011      1.164          5        640: 100%|| 1324/1324 [04:26<00:00,  4.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.25it/s]\n                   all       2046       2132      0.972      0.928      0.973      0.653\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      2.74G      1.091     0.5089      1.174          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.20it/s]\n                   all       2046       2132      0.971      0.935      0.972      0.655\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      2.74G      1.096     0.5128      1.181          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.963      0.937       0.97      0.639\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      2.74G      1.083     0.4937      1.171          5        640: 100%|| 1324/1324 [04:17<00:00,  5.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.23it/s]\n                   all       2046       2132       0.97      0.931      0.972      0.663\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      2.74G      1.087     0.4927      1.172          5        640: 100%|| 1324/1324 [04:17<00:00,  5.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.21it/s]\n                   all       2046       2132      0.975      0.933      0.976      0.658\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      2.74G      1.068     0.4728      1.161          5        640: 100%|| 1324/1324 [04:17<00:00,  5.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.19it/s]\n                   all       2046       2132      0.974      0.937      0.971       0.66\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      2.74G      1.049     0.4591      1.152          4        640: 100%|| 1324/1324 [04:16<00:00,  5.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.27it/s]\n                   all       2046       2132       0.98       0.95       0.98      0.666\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      2.74G      1.035      0.437      1.137          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.19it/s]\n                   all       2046       2132      0.977      0.947       0.98      0.682\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      2.74G      1.025     0.4224      1.134          5        640: 100%|| 1324/1324 [04:16<00:00,  5.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.21it/s]\n                   all       2046       2132      0.982      0.947      0.981      0.683\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/10      2.74G      1.001     0.4052      1.116          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.58it/s]\n                   all       2046       2132      0.978      0.953      0.981      0.687\n\n10 epochs completed in 0.767 hours.\nOptimizer stripped from logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052/weights/last.pt, 6.2MB\nOptimizer stripped from logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052/weights/best.pt, 6.2MB\n\nValidating logs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.69it/s]\n                   all       2046       2132      0.978      0.953      0.981      0.687\nSpeed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/licenceplate-learning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.00052\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005, name=learning-rate0.1_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/train/labels.cache... 21173 images, 28 backgrounds, 0 corrupt: 100%|| 21173/21173 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/valid/labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|| 2046/2046 [00:00<?, ?it/s]\nPlotting labels to logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      2.82G      1.535      1.137       1.66          5        640: 100%|| 1324/1324 [04:26<00:00,  4.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.639      0.545      0.598      0.291\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      2.74G      1.478      1.037      1.608          5        640: 100%|| 1324/1324 [04:26<00:00,  4.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:16<00:00,  3.79it/s]\n                   all       2046       2132      0.906      0.769      0.849      0.448\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      2.74G      1.429     0.9905      1.568          5        640: 100%|| 1324/1324 [04:22<00:00,  5.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.24it/s]\n                   all       2046       2132      0.911      0.802       0.86      0.476\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      2.74G      1.394     0.9148      1.534          5        640: 100%|| 1324/1324 [04:19<00:00,  5.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.17it/s]\n                   all       2046       2132      0.923      0.837      0.888      0.528\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      2.74G      1.377     0.8931      1.526          5        640: 100%|| 1324/1324 [04:18<00:00,  5.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.07it/s]\n                   all       2046       2132       0.87      0.741      0.818      0.452\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      2.75G       1.35     0.8572      1.503          5        640: 100%|| 1324/1324 [04:21<00:00,  5.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.16it/s]\n                   all       2046       2132      0.931      0.834      0.879      0.478\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      2.74G      1.328     0.8152      1.479          4        640: 100%|| 1324/1324 [04:19<00:00,  5.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.21it/s]\n                   all       2046       2132      0.931      0.857      0.919      0.517\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      2.74G      1.311     0.7804      1.455          5        640: 100%|| 1324/1324 [04:18<00:00,  5.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.11it/s]\n                   all       2046       2132      0.913      0.866      0.918      0.526\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      2.74G       1.29      0.739      1.432          5        640: 100%|| 1324/1324 [04:16<00:00,  5.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.20it/s]\n                   all       2046       2132      0.936      0.874      0.926      0.545\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/10      2.74G      1.261     0.6962      1.402          5        640: 100%|| 1324/1324 [04:19<00:00,  5.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.58it/s]\n                   all       2046       2132      0.952      0.879      0.932      0.539\n\n10 epochs completed in 0.774 hours.\nOptimizer stripped from logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:17<00:00,  3.65it/s]\n                   all       2046       2132      0.935      0.874      0.926      0.545\nSpeed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/licenceplate-learning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Licence plate recognition/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/licenceplate-learning-rate0.1_momentum0.99_weight_decay0.0005, name=learning-rate0.1_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/licenceplate-learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/licenceplate-learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/train/labels.cache... 21173 images, 28 backgrounds, 0 corrupt: 100%|| 21173/21173 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Licence plate recognition/valid/labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|| 2046/2046 [00:00<?, ?it/s]\nPlotting labels to logs/licenceplate-learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/licenceplate-learning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      2.82G      1.283      0.741      1.438          5        640: 100%|| 1324/1324 [04:26<00:00,  4.96it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 64/64 [00:15<00:00,  4.12it/s]\n                   all       2046       2132      0.953      0.812      0.909      0.517\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      2.74G      1.332     0.8277       1.51          5        640: 100%|| 1324/1324 [04:20<00:00,  5.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  91%| | 58/64 [00:14<00:01,  4.25it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# import csv\n# from ultralytics import YOLO\n# import os\n\n# # Define a YOLOv8n model\n# model = YOLO('yolov8n.pt')\n\n# # Define the hyperparameters to tune\n# lr0_values = [0.001, 0.1]\n# momentum_values = [0.8, 0.99]\n# weight_decay_values = [0.0005]\n# optimizer = 'SGD'\n# epochs = 15\n\n# # Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset\n# best_loss = float('inf')\n# best_hyperparameters = {}\n\n# data = '/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml'\n\n# with open('hyperparameters4.csv', mode='w') as csv_file:\n#     fieldnames = ['lr0', 'momentum', 'weight_decay', 'val_loss']\n#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n#     writer.writeheader()\n\n#     for lr0 in lr0_values:\n#         for momentum in momentum_values:\n#             for weight_decay in weight_decay_values:\n#                 save_dir = f'logs/AerialcarviewSGDlearning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}'\n#                 os.makedirs(save_dir, exist_ok=True)\n#                 result = model.train(data=data, lr0=lr0, momentum=momentum, weight_decay=weight_decay, optimizer=optimizer, epochs=epochs,\n#                                      plots=True, project=save_dir, name=f'learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}' )\n\n#                 writer.writerow({'lr0': lr0, 'momentum': momentum, 'weight_decay': weight_decay})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:38.975199Z","iopub.execute_input":"2024-01-14T15:36:38.975943Z","iopub.status.idle":"2024-01-14T15:50:29.143271Z","shell.execute_reply.started":"2024-01-14T15:36:38.975905Z","shell.execute_reply":"2024-01-14T15:50:29.142213Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"New https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005, name=learning-rate0.001_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      4.62G      1.061      2.599      1.079         65        640: 100%|| 40/40 [00:11<00:00,  3.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.82it/s]\n                   all         60        988     0.0547      0.997      0.894      0.646\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.79G     0.9557      1.439     0.9725         58        640: 100%|| 40/40 [00:11<00:00,  3.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.81it/s]\n                   all         60        988      0.929      0.912      0.969      0.734\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.44G       0.91      1.051     0.9413         73        640: 100%|| 40/40 [00:11<00:00,  3.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.84it/s]\n                   all         60        988      0.963      0.968      0.988      0.767\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.64G     0.8544     0.9063     0.9225         73        640: 100%|| 40/40 [00:11<00:00,  3.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.83it/s]\n                   all         60        988      0.973      0.976      0.991      0.789\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.68G     0.8614     0.8614     0.9256         91        640: 100%|| 40/40 [00:10<00:00,  3.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.93it/s]\n                   all         60        988      0.981      0.979      0.993      0.787\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.56G     0.8034     0.9076     0.9089         31        640: 100%|| 40/40 [00:11<00:00,  3.55it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.71it/s]\n                   all         60        988      0.977      0.984      0.993      0.793\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      2.98G     0.7926     0.8536     0.9072         71        640: 100%|| 40/40 [00:09<00:00,  4.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.94it/s]\n                   all         60        988      0.974      0.989      0.993        0.8\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.43G     0.7835     0.8317      0.913         75        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.95it/s]\n                   all         60        988      0.979      0.987      0.993      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15       3.2G     0.7838      0.814     0.9135         41        640: 100%|| 40/40 [00:09<00:00,  4.06it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.89it/s]\n                   all         60        988      0.976      0.988      0.993        0.8\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15       2.9G     0.7692     0.7835     0.9009         53        640: 100%|| 40/40 [00:09<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.97it/s]\n                   all         60        988      0.978      0.988      0.993      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.03G     0.7714     0.7779     0.9036         51        640: 100%|| 40/40 [00:09<00:00,  4.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.90it/s]\n                   all         60        988      0.978      0.988      0.994      0.807\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.91G     0.7752     0.7678     0.9033         57        640: 100%|| 40/40 [00:09<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.97it/s]\n                   all         60        988      0.979       0.99      0.993      0.806\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.53G     0.7663     0.7527     0.9055         40        640: 100%|| 40/40 [00:09<00:00,  4.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.87it/s]\n                   all         60        988      0.979      0.988      0.994      0.808\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.14G     0.7687     0.7639     0.9024         54        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.91it/s]\n                   all         60        988      0.978       0.99      0.994      0.808\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.92G     0.7679     0.7612     0.9048         20        640: 100%|| 40/40 [00:09<00:00,  4.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:02<00:00,  1.03s/it]\n                   all         60        988      0.978       0.99      0.994      0.807\n\n15 epochs completed in 0.053 hours.\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.07it/s]\n                   all         60        988      0.978       0.99      0.994      0.808\nSpeed: 1.4ms preprocess, 2.9ms inference, 0.0ms loss, 8.4ms postprocess per image\nResults saved to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005, name=learning-rate0.001_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.14G     0.7651     0.6825     0.9034         48        640: 100%|| 40/40 [00:10<00:00,  3.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.33it/s]\n                   all         60        988      0.977      0.989      0.994      0.808\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.01G     0.7742        0.6     0.9037         67        640: 100%|| 40/40 [00:09<00:00,  4.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.60it/s]\n                   all         60        988       0.98      0.987      0.993      0.804\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.08G     0.7708     0.5778     0.9046         26        640: 100%|| 40/40 [00:09<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]\n                   all         60        988       0.98      0.985      0.993        0.8\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.43G     0.7761     0.5615     0.9054         19        640: 100%|| 40/40 [00:09<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.65it/s]\n                   all         60        988       0.98      0.988      0.993        0.8\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.29G     0.7627     0.5423     0.8997         79        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.24it/s]\n                   all         60        988      0.984      0.984      0.993      0.798\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.55G     0.7493     0.5248     0.8915         31        640: 100%|| 40/40 [00:10<00:00,  3.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.71it/s]\n                   all         60        988      0.974      0.992      0.993      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      2.98G     0.7399     0.4991     0.8915         71        640: 100%|| 40/40 [00:09<00:00,  4.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.41it/s]\n                   all         60        988      0.978       0.99      0.993      0.798\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.42G     0.7323     0.4945     0.8958         75        640: 100%|| 40/40 [00:09<00:00,  4.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.60it/s]\n                   all         60        988      0.981      0.985      0.993      0.801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15      3.19G     0.7295     0.4841     0.8975         41        640: 100%|| 40/40 [00:09<00:00,  4.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.51it/s]\n                   all         60        988      0.978      0.993      0.992      0.795\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15       2.9G     0.7188     0.4683     0.8872         53        640: 100%|| 40/40 [00:09<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]\n                   all         60        988      0.975      0.992      0.994      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.02G     0.7193     0.4622     0.8877         51        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.50it/s]\n                   all         60        988      0.988      0.982      0.993      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15       2.9G     0.7219     0.4559     0.8875         57        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.79it/s]\n                   all         60        988      0.989      0.983      0.993      0.795\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.53G     0.7056     0.4432      0.887         40        640: 100%|| 40/40 [00:09<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.52it/s]\n                   all         60        988      0.985      0.984      0.993      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.14G     0.7124     0.4498     0.8862         54        640: 100%|| 40/40 [00:09<00:00,  4.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988      0.982      0.987      0.993      0.803\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.92G     0.7052     0.4448     0.8863         20        640: 100%|| 40/40 [00:09<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.06it/s]\n                   all         60        988      0.984      0.987      0.993      0.804\n\n15 epochs completed in 0.052 hours.\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.14it/s]\n                   all         60        988      0.977      0.989      0.993      0.807\nSpeed: 1.6ms preprocess, 2.9ms inference, 0.0ms loss, 3.8ms postprocess per image\nResults saved to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005, name=learning-rate0.1_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.1, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.16G      1.169     0.9362       1.08         48        640: 100%|| 40/40 [00:10<00:00,  3.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988       0.85      0.932      0.909      0.542\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15         3G      1.505      1.395      1.321         67        640: 100%|| 40/40 [00:09<00:00,  4.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.73it/s]\n                   all         60        988      0.323      0.334      0.228     0.0708\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15       3.1G      1.754      1.697      1.583         26        640: 100%|| 40/40 [00:09<00:00,  4.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.08it/s]\n                   all         60        988     0.0549     0.0901     0.0245    0.00622\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.44G      1.743      1.626      1.508         19        640: 100%|| 40/40 [00:09<00:00,  4.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.70it/s]\n                   all         60        988      0.229      0.179      0.107     0.0373\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15       3.3G       1.62      1.302      1.367         79        640: 100%|| 40/40 [00:09<00:00,  4.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.82it/s]\n                   all         60        988       0.44      0.713      0.402      0.196\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.56G      1.441      1.127      1.322         31        640: 100%|| 40/40 [00:11<00:00,  3.57it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.71it/s]\n                   all         60        988      0.881      0.897      0.936      0.536\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      2.99G       1.33     0.8593      1.217         71        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.50it/s]\n                   all         60        988      0.931      0.925      0.966      0.649\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.43G      1.156     0.7369      1.119         75        640: 100%|| 40/40 [00:09<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.70it/s]\n                   all         60        988      0.971      0.952      0.984      0.645\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15       3.2G      1.099     0.6636      1.097         41        640: 100%|| 40/40 [00:09<00:00,  4.00it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988      0.977      0.963      0.985      0.685\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15      2.91G      1.024     0.6066      1.055         53        640: 100%|| 40/40 [00:09<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.55it/s]\n                   all         60        988      0.971      0.963       0.99      0.726\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.03G     0.9868     0.5554      1.025         51        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.71it/s]\n                   all         60        988      0.984      0.975      0.991      0.749\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.92G     0.9223     0.5307     0.9951         57        640: 100%|| 40/40 [00:09<00:00,  4.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.95it/s]\n                   all         60        988      0.989      0.973      0.992      0.743\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.53G     0.8737     0.4916     0.9807         40        640: 100%|| 40/40 [00:09<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.69it/s]\n                   all         60        988      0.979      0.978      0.992      0.779\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.15G     0.8366     0.4763     0.9591         54        640: 100%|| 40/40 [00:09<00:00,  4.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.24it/s]\n                   all         60        988      0.982      0.977      0.992      0.794\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.93G     0.8001     0.4532      0.945         20        640: 100%|| 40/40 [00:09<00:00,  4.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.05it/s]\n                   all         60        988      0.982      0.976      0.992      0.798\n\n15 epochs completed in 0.056 hours.\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.26it/s]\n                   all         60        988      0.983      0.976      0.992      0.798\nSpeed: 1.6ms preprocess, 3.3ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005, name=learning-rate0.1_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.1, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.15G     0.8253     0.4676     0.9534         48        640: 100%|| 40/40 [00:10<00:00,  3.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.75it/s]\n                   all         60        988      0.975      0.976      0.992      0.748\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.05G      1.004     0.5623      1.038         67        640: 100%|| 40/40 [00:09<00:00,  4.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988      0.959      0.896      0.968      0.643\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.11G      1.175     0.6995      1.121         26        640: 100%|| 40/40 [00:09<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.23it/s]\n                   all         60        988     0.0922      0.116     0.0374     0.0105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.43G      1.187     0.7697      1.136         19        640: 100%|| 40/40 [00:09<00:00,  4.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.86it/s]\n                   all         60        988      0.171      0.217      0.119     0.0412\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.29G      1.182     0.7612      1.139         79        640: 100%|| 40/40 [00:09<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.01it/s]\n                   all         60        988      0.353      0.596      0.351      0.162\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.55G      1.095     0.6837      1.114         31        640: 100%|| 40/40 [00:11<00:00,  3.62it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.98it/s]\n                   all         60        988      0.545      0.675       0.57      0.314\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      2.98G       1.02      0.619       1.07         71        640: 100%|| 40/40 [00:09<00:00,  4.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.89it/s]\n                   all         60        988      0.624      0.863      0.683       0.44\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.42G     0.9477     0.5591      1.045         75        640: 100%|| 40/40 [00:09<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.68it/s]\n                   all         60        988      0.753      0.902       0.82      0.565\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15      3.19G     0.9163     0.5293      1.033         41        640: 100%|| 40/40 [00:09<00:00,  4.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.72it/s]\n                   all         60        988      0.696      0.901      0.749      0.505\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15       2.9G     0.8732     0.5015      1.003         53        640: 100%|| 40/40 [00:09<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.86it/s]\n                   all         60        988       0.87      0.951      0.929      0.688\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.02G     0.8567     0.4816     0.9874         51        640: 100%|| 40/40 [00:09<00:00,  4.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.85it/s]\n                   all         60        988      0.896      0.951      0.954      0.724\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15       2.9G     0.8376     0.4613      0.982         57        640: 100%|| 40/40 [00:09<00:00,  4.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.80it/s]\n                   all         60        988      0.953      0.973      0.981      0.745\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.53G     0.8089     0.4322     0.9727         40        640: 100%|| 40/40 [00:09<00:00,  4.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.60it/s]\n                   all         60        988      0.956      0.982      0.988       0.76\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.14G     0.8041     0.4304     0.9675         54        640: 100%|| 40/40 [00:09<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.69it/s]\n                   all         60        988      0.972      0.979      0.991      0.792\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.92G     0.7858     0.4148     0.9577         20        640: 100%|| 40/40 [00:09<00:00,  4.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.08it/s]\n                   all         60        988      0.983      0.976      0.992      0.793\n\n15 epochs completed in 0.055 hours.\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.33it/s]\n                   all         60        988      0.983      0.976      0.992      0.794\nSpeed: 1.4ms preprocess, 2.8ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/AerialcarviewSGDlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# import csv\n# from ultralytics import YOLO\n# import os\n\n# # Define a YOLOv8n model\n# model = YOLO('yolov8n.pt')\n\n# # Define the hyperparameters to tune\n# lr0_values = [0.001, 0.1]\n# momentum_values = [0.8, 0.99]\n# weight_decay_values = [0.0005]\n# optimizer = 'Adam'\n# epochs = 15\n\n# # Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset\n# best_loss = float('inf')\n# best_hyperparameters = {}\n\n# data = '/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml'\n\n# with open('hyperparameters3.csv', mode='w') as csv_file:\n#     fieldnames = ['lr0', 'momentum', 'weight_decay', 'val_loss']\n#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n#     writer.writeheader()\n\n#     for lr0 in lr0_values:\n#         for momentum in momentum_values:\n#             for weight_decay in weight_decay_values:\n#                 save_dir = f'logs/Aerialcarviewlearning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}'\n#                 os.makedirs(save_dir, exist_ok=True)\n#                 result = model.train(data=data, lr0=lr0, momentum=momentum, weight_decay=weight_decay, optimizer=optimizer, epochs=epochs,\n#                                      plots=True, project=save_dir, name=f'learning-rate{lr0}_momentum{momentum}_weight_decay{weight_decay}' )\n\n#                 writer.writerow({'lr0': lr0, 'momentum': momentum, 'weight_decay': weight_decay})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:50:29.145746Z","iopub.execute_input":"2024-01-14T15:50:29.146713Z","iopub.status.idle":"2024-01-14T16:05:04.440242Z","shell.execute_reply.started":"2024-01-14T15:50:29.146667Z","shell.execute_reply":"2024-01-14T16:05:04.438853Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"New https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005, name=learning-rate0.001_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      4.34G     0.9652      1.387     0.9587         65        640: 100%|| 40/40 [00:11<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.27it/s]\n                   all         60        988      0.968       0.93      0.982      0.751\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.79G     0.8999      0.648     0.9306         58        640: 100%|| 40/40 [00:11<00:00,  3.54it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.35it/s]\n                   all         60        988      0.968      0.979      0.992       0.77\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.44G     0.8766     0.5775     0.9285         73        640: 100%|| 40/40 [00:11<00:00,  3.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]\n                   all         60        988      0.985      0.979      0.993      0.788\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.64G     0.8207     0.5192      0.913         73        640: 100%|| 40/40 [00:11<00:00,  3.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.54it/s]\n                   all         60        988      0.981       0.98      0.993      0.798\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.68G     0.8356     0.5107     0.9209         91        640: 100%|| 40/40 [00:10<00:00,  3.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.54it/s]\n                   all         60        988      0.981      0.987      0.991      0.788\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.55G     0.7878     0.5007     0.9032         31        640: 100%|| 40/40 [00:11<00:00,  3.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.50it/s]\n                   all         60        988       0.97      0.989      0.993      0.777\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      2.98G      0.777     0.4674     0.9006         71        640: 100%|| 40/40 [00:09<00:00,  4.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.92it/s]\n                   all         60        988       0.98      0.986      0.994      0.789\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.43G     0.7535     0.4511     0.9048         75        640: 100%|| 40/40 [00:09<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.60it/s]\n                   all         60        988      0.985      0.985      0.994      0.792\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15       3.2G     0.7529     0.4381      0.905         41        640: 100%|| 40/40 [00:09<00:00,  4.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.63it/s]\n                   all         60        988      0.985      0.982      0.993      0.788\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15       2.9G     0.7369     0.4136     0.8931         53        640: 100%|| 40/40 [00:09<00:00,  4.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.58it/s]\n                   all         60        988      0.988       0.98      0.993      0.797\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.03G     0.7232     0.4041     0.8906         51        640: 100%|| 40/40 [00:09<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.76it/s]\n                   all         60        988      0.987      0.978      0.992      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.91G     0.7224     0.3992     0.8908         57        640: 100%|| 40/40 [00:10<00:00,  3.89it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.83it/s]\n                   all         60        988      0.985      0.987      0.993      0.805\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.53G     0.7023     0.3792     0.8885         40        640: 100%|| 40/40 [00:09<00:00,  4.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.67it/s]\n                   all         60        988      0.987      0.978      0.993      0.797\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.14G     0.6997     0.3847     0.8855         54        640: 100%|| 40/40 [00:09<00:00,  4.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.25it/s]\n                   all         60        988      0.989      0.982      0.994      0.803\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.92G      0.688     0.3709     0.8816         20        640: 100%|| 40/40 [00:09<00:00,  4.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.13it/s]\n                   all         60        988      0.989      0.983      0.993      0.803\n\n15 epochs completed in 0.053 hours.\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.23it/s]\n                   all         60        988      0.985      0.987      0.993      0.805\nSpeed: 1.6ms preprocess, 3.1ms inference, 0.0ms loss, 1.4ms postprocess per image\nResults saved to \u001b[1mlogs/Aerialcarviewlearning-rate0.001_momentum0.8_weight_decay0.0005/learning-rate0.001_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005, name=learning-rate0.001_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.18G     0.7595     0.4183     0.9012         48        640: 100%|| 40/40 [00:10<00:00,  3.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.99it/s]\n                   all         60        988       0.98      0.978      0.993      0.766\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.02G     0.7723     0.4347     0.9074         67        640: 100%|| 40/40 [00:09<00:00,  4.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.20it/s]\n                   all         60        988      0.983      0.963      0.991      0.788\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.11G     0.7661     0.4431     0.9128         26        640: 100%|| 40/40 [00:09<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.92it/s]\n                   all         60        988      0.976      0.973      0.991      0.792\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.46G     0.7691     0.4348     0.9126         19        640: 100%|| 40/40 [00:09<00:00,  4.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.78it/s]\n                   all         60        988      0.986       0.98      0.992      0.801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.32G     0.7541     0.4198     0.9056         79        640: 100%|| 40/40 [00:09<00:00,  4.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.75it/s]\n                   all         60        988      0.982      0.984      0.991      0.797\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.58G     0.7329     0.4088     0.8951         31        640: 100%|| 40/40 [00:11<00:00,  3.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.98it/s]\n                   all         60        988      0.984      0.983      0.993      0.804\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      3.01G     0.7216     0.3949     0.8938         71        640: 100%|| 40/40 [00:09<00:00,  4.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.67it/s]\n                   all         60        988      0.985      0.983      0.992      0.797\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.45G     0.7174     0.3919     0.8986         75        640: 100%|| 40/40 [00:09<00:00,  4.06it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.93it/s]\n                   all         60        988      0.987      0.981      0.993      0.805\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15      3.22G      0.716     0.3853     0.9007         41        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.78it/s]\n                   all         60        988      0.985      0.983      0.992      0.798\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15      2.93G     0.7005     0.3754     0.8886         53        640: 100%|| 40/40 [00:09<00:00,  4.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.88it/s]\n                   all         60        988      0.986      0.979      0.992      0.804\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.05G     0.6973     0.3678      0.888         51        640: 100%|| 40/40 [00:09<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988      0.982      0.983      0.992       0.81\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.93G     0.6977     0.3637     0.8883         57        640: 100%|| 40/40 [00:09<00:00,  4.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.98it/s]\n                   all         60        988      0.985      0.978      0.991      0.811\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.55G     0.6855     0.3548      0.888         40        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.58it/s]\n                   all         60        988      0.983      0.981      0.992      0.821\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.16G     0.6922     0.3588     0.8873         54        640: 100%|| 40/40 [00:09<00:00,  4.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.68it/s]\n                   all         60        988      0.988      0.977      0.992      0.817\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.94G     0.6757     0.3463     0.8826         20        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.12it/s]\n                   all         60        988      0.988       0.98      0.993      0.819\n\n15 epochs completed in 0.054 hours.\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.25it/s]\n                   all         60        988      0.983      0.981      0.992      0.821\nSpeed: 1.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/Aerialcarviewlearning-rate0.001_momentum0.99_weight_decay0.0005/learning-rate0.001_momentum0.99_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005, name=learning-rate0.1_momentum0.8_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.8, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.8) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.12G       2.99      2.686      2.575         48        640: 100%|| 40/40 [00:10<00:00,  3.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.75it/s]\n                   all         60        988   0.000944     0.0172   0.000492   0.000132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15         3G      2.547      2.106       2.28         67        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.18it/s]\n                   all         60        988    0.00156     0.0283   0.000809    0.00022\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15       3.1G      2.482      2.189      2.354         26        640: 100%|| 40/40 [00:09<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.96it/s]\n                   all         60        988     0.0267      0.174     0.0157    0.00431\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.45G      2.274      2.011      2.092         19        640: 100%|| 40/40 [00:09<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.09it/s]\n                   all         60        988      0.217      0.391      0.198     0.0636\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.31G      2.132      1.839      1.924         79        640: 100%|| 40/40 [00:10<00:00,  3.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.43it/s]\n                   all         60        988      0.319      0.324      0.226     0.0813\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.53G      2.032      1.723      1.891         31        640: 100%|| 40/40 [00:10<00:00,  3.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.17it/s]\n                   all         60        988     0.0186      0.338     0.0125    0.00366\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15         3G      1.836      1.472      1.693         71        640: 100%|| 40/40 [00:09<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.55it/s]\n                   all         60        988      0.282      0.382      0.329      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.44G      1.686      1.326      1.596         75        640: 100%|| 40/40 [00:10<00:00,  3.99it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.65it/s]\n                   all         60        988      0.525      0.519      0.568      0.222\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15      3.21G      1.583      1.241       1.51         41        640: 100%|| 40/40 [00:09<00:00,  4.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.93it/s]\n                   all         60        988      0.699      0.667      0.733      0.346\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15      2.92G      1.557      1.143       1.46         53        640: 100%|| 40/40 [00:09<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.89it/s]\n                   all         60        988      0.837      0.741      0.858      0.424\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.04G       1.47      1.038      1.397         51        640: 100%|| 40/40 [00:09<00:00,  4.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.81it/s]\n                   all         60        988      0.818      0.736      0.841      0.407\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.92G      1.395      0.993      1.332         57        640: 100%|| 40/40 [00:09<00:00,  4.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.90it/s]\n                   all         60        988      0.877      0.816      0.911      0.569\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.54G      1.332     0.9083        1.3         40        640: 100%|| 40/40 [00:09<00:00,  4.06it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.95it/s]\n                   all         60        988      0.864      0.856       0.93      0.586\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.16G      1.295     0.8552      1.269         54        640: 100%|| 40/40 [00:09<00:00,  4.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.76it/s]\n                   all         60        988      0.921      0.911      0.967      0.675\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.94G      1.234     0.7945       1.23         20        640: 100%|| 40/40 [00:09<00:00,  4.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.14it/s]\n                   all         60        988      0.946      0.907      0.971      0.667\n\n15 epochs completed in 0.051 hours.\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.20it/s]\n                   all         60        988      0.922      0.911      0.967      0.675\nSpeed: 1.7ms preprocess, 2.7ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mlogs/Aerialcarviewlearning-rate0.1_momentum0.8_weight_decay0.0005/learning-rate0.1_momentum0.8_weight_decay0.0005\u001b[0m\nNew https://pypi.org/project/ultralytics/8.1.1 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nWARNING  Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dlprojectcombined/Aerial car view yolo dataset/data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005, name=learning-rate0.1_momentum0.99_weight_decay0.0005, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.99, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3011043 parameters, 3011027 gradients\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/train/labels.cache... 627 images, 0 backgrounds, 0 corrupt: 100%|| 627/627 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dlprojectcombined/Aerial car view yolo dataset/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|| 60/60 [00:00<?, ?it/s]\nPlotting labels to logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.99) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mlogs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/15      3.16G      1.341     0.8842      1.289         48        640: 100%|| 40/40 [00:10<00:00,  3.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.90it/s]\n                   all         60        988      0.765      0.665      0.767       0.31\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/15      3.07G      1.371     0.9464      1.321         67        640: 100%|| 40/40 [00:10<00:00,  4.00it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.92it/s]\n                   all         60        988      0.638      0.378      0.462      0.229\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/15      3.17G      1.398     0.9386      1.337         26        640: 100%|| 40/40 [00:09<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.76it/s]\n                   all         60        988      0.731      0.653      0.692      0.294\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/15      3.47G      1.338     0.9088      1.284         19        640: 100%|| 40/40 [00:09<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.71it/s]\n                   all         60        988      0.912       0.86      0.943      0.617\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/15      3.32G        1.3     0.8626       1.26         79        640: 100%|| 40/40 [00:09<00:00,  4.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.64it/s]\n                   all         60        988      0.893      0.817      0.911      0.562\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/15      3.58G      1.281     0.8312      1.237         31        640: 100%|| 40/40 [00:11<00:00,  3.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988      0.911      0.878      0.957      0.636\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/15      3.01G      1.243     0.8238      1.214         71        640: 100%|| 40/40 [00:09<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.61it/s]\n                   all         60        988      0.891       0.88      0.951      0.639\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/15      3.45G       1.23     0.7749      1.205         75        640: 100%|| 40/40 [00:09<00:00,  4.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.80it/s]\n                   all         60        988      0.906      0.907      0.965      0.634\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/15      3.22G      1.214     0.7668      1.208         41        640: 100%|| 40/40 [00:09<00:00,  4.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.69it/s]\n                   all         60        988      0.912      0.924      0.968      0.665\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/15      2.93G      1.157     0.7389      1.179         53        640: 100%|| 40/40 [00:09<00:00,  4.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.43it/s]\n                   all         60        988      0.946      0.941       0.98      0.705\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/15      3.05G      1.146     0.7128      1.154         51        640: 100%|| 40/40 [00:09<00:00,  4.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]\n                   all         60        988      0.936      0.936      0.978      0.693\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/15      2.93G      1.126     0.6992      1.146         57        640: 100%|| 40/40 [00:09<00:00,  4.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.74it/s]\n                   all         60        988       0.95      0.929      0.979      0.702\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/15      3.55G      1.095      0.676      1.134         40        640: 100%|| 40/40 [00:09<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.72it/s]\n                   all         60        988       0.94      0.943      0.983      0.727\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/15      3.16G      1.095     0.6789      1.125         54        640: 100%|| 40/40 [00:09<00:00,  4.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.93it/s]\n                   all         60        988      0.944      0.941      0.983      0.728\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/15      2.94G      1.068     0.6553      1.115         20        640: 100%|| 40/40 [00:09<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.11it/s]\n                   all         60        988      0.942      0.954      0.986      0.737\n\n15 epochs completed in 0.057 hours.\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/last.pt, 6.2MB\nOptimizer stripped from logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt, 6.2MB\n\nValidating logs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005/weights/best.pt...\nUltralytics YOLOv8.0.145  Python-3.7.12 torch-1.11.0 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.30it/s]\n                   all         60        988      0.942      0.954      0.986      0.738\nSpeed: 1.7ms preprocess, 3.1ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mlogs/Aerialcarviewlearning-rate0.1_momentum0.99_weight_decay0.0005/learning-rate0.1_momentum0.99_weight_decay0.0005\u001b[0m\n","output_type":"stream"}]}]}